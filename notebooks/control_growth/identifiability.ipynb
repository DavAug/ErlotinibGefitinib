{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifiability of Structural Growth Model in Absence of Compound\n",
    "\n",
    "The tumour growth inhibiting effects of Erlotinib and Gefitinib were modelled with a population PKPD model in [1]. A population PKPD model is a hierarchical model which consists of a structural model, a population model, and an error model. Each sub-model captures a different aspect of the tumour growth inhibition biology, and is parametrised by a set of parameters. \n",
    "\n",
    "In this notebook we explore the identifiability of the structural model reported in [1] in absence of the compound. In particular we investigate the effect of log-transforms and non-dimensionalisation of the model parameters on the stability of the inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural growth model in absence of the compound\n",
    "\n",
    "In a PKPD model the structural model is a mechanistic or empirical description of the drug's pharmacokinetics and pharmacodynamics. However, a good PKPD model also needs to capture the biology well in absence of the drug, in order to predict it's effects properly. In this study this means that we need to have a good understanding of the tumour growth in absence of the compund. In [1] a structural model is proposed, which assumes that the tumour grows exponentially for small tumour volumes, and linearly for large tumour volumes\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\text{d}V^s_T}{\\text{d}t} = \\frac{2\\lambda _0\\lambda _1 V^s_T}{2\\lambda _0 V^s_T + \\lambda _1}.\n",
    "\\end{equation*}\n",
    "\n",
    "Here, $V^s_T$ is the predicted tumour volume by the structural model, $\\lambda _0$ is the exponential growth rate, and $\\lambda _1$ is the linear growth rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifiability\n",
    "\n",
    "The problem of the identifiability of non-linear ordinary differential equation (ODE) models is a multifacetted problem and has been addressed many times in the literature, e.g. [2, 3, 4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the parameters $V_0$, $\\lambda _0$ and $\\lambda _1$ that best describe the observed tumour growth in untreated mice, see the dedicated [notebook](https://nbviewer.jupyter.org/github/DavAug/ErlotinibGefitinib/blob/master/notebooks/control_growth/data_preparation.ipynb) for details on the data. Here $V_0$ is the initial tumour volume at time $t=0$ according to the structural model, i.e. $V^s_T(t=0)=V_0$. In order to find good parameters we will use Bayesian inference. Bayesian inference constructs distributions for the parameters $V_0$, $\\lambda _0$ and $\\lambda _1$, indicating the probability with which certain parameter values have generated the data.\n",
    "\n",
    "In this notebook we want to make sure that \n",
    "\n",
    "- identifiability: technical challenges versus theoretical problems\n",
    "- discuss reasons for non-dimensionalisation\n",
    "    - in theory Bayesian inference works for any model\n",
    "    - in practice performance is a lot improved by by having parameters of equal scale (most optimisation have only one step size)\n",
    "    - avoid hard boundaries, discuss why\n",
    "- model can be such that it's overparametrised\n",
    "- or data does not provide enough information about data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of naïve pooled model\n",
    "\n",
    "We are using [myokit](http://myokit.org/) for the implementation of the structural model. Myokit enables us to solve the structural model ODE with an adaptive numerical solver called CVODE [3]. To implement the error model and perform the inference we are using [pints](https://pints.readthedocs.io/). \n",
    "\n",
    "Note that in general the quality of the inference of $\\psi $ and $\\theta _V$ can be significantly improved when all parameters are appropriately transformed. We will however choose to not transform the parameetrs at first, to illustrate how the inference may be stabilised with transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of structural model in myokit\n",
    "\n",
    "We have implemented the structural model in myokit with untransformed parameters in a separate [module](https://github.com/DavAug/ErlotinibGefitinib/blob/master/pkpd/model.py). The structural model can now be created by calling ```pkpd.model.create_tumour_growth_model()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[model]]\n# Initial values\ncentral.volume_t = 0\n\n[central]\nlambda_0 = 0\n    in [1/day]\nlambda_1 = 1\n    in [cm^3/day]\ntime = 0 bind time\n    in [day]\ndot(volume_t) = 2 * (lambda_0 * (lambda_1 * volume_t)) / (2 * (lambda_0 * volume_t) + lambda_1)\n    in [cm^3]\n\n\n"
    }
   ],
   "source": [
    "#\n",
    "# Implementing the structural model in myokit.\n",
    "#\n",
    "\n",
    "from pkpd import model as m\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = m.create_tumour_growth_model()\n",
    "\n",
    "# Print structural model\n",
    "print(model.code())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of error model \n",
    "We use pints to implement the error model indirectly by defining a log-likelihood for the model parameters $\\psi $ and $\\theta _V$\n",
    "\n",
    "\\begin{equation*}\n",
    "L(\\psi , \\theta _V | V^{\\text{obs}}_T) = \\mathbb{P}(V_T | \\psi , \\theta _V) \\Big | _{V_T = V^{\\text{obs}}_T} .\n",
    "\\end{equation*}\n",
    "\n",
    "Note that here the likelihood is mathematically equivalent to the above defined distribution of tumour growth curves.\n",
    "\n",
    "To use the structural model in pints we first need to wrap the myokit model by a `pints.ForwardModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define pints model wrapper such that myokit model can be used for inference.\n",
    "#\n",
    "\n",
    "import myokit\n",
    "import pints\n",
    "\n",
    "from pkpd import model as model\n",
    "\n",
    "\n",
    "# Wrap myokit model, so it can be used with pints\n",
    "class PintsModel(pints.ForwardModel):\n",
    "    def __init__(self):\n",
    "        # Create myokit model\n",
    "        model = m.create_tumour_growth_model()\n",
    "\n",
    "        # Create simulator\n",
    "        self.sim = myokit.Simulation(model)\n",
    "\n",
    "    def n_parameters(self):\n",
    "        \"\"\"\n",
    "        Number of parameters to fit. Here initial V^s_T, lambda_0, lambda_1\n",
    "        \"\"\"\n",
    "        return 3\n",
    "\n",
    "    def n_outputs(self):\n",
    "        return 1\n",
    "\n",
    "    def simulate(self, parameters, times):\n",
    "        # Reset simulation\n",
    "        self.sim.reset()\n",
    "\n",
    "        # Sort input parameters\n",
    "        initial_volume, lambda_0, lambda_1 = parameters\n",
    "\n",
    "        # Set initial condition\n",
    "        self.sim.set_state([initial_volume])\n",
    "\n",
    "        # Set growth constants\n",
    "        self.sim.set_constant('central.lambda_0', lambda_0)\n",
    "        self.sim.set_constant('central.lambda_1', lambda_1)\n",
    "\n",
    "        # Define logged variable\n",
    "        loggedVariable = 'central.volume_t'\n",
    "\n",
    "        # Simulate\n",
    "        output = self.sim.run(times[-1] + 1, log=[loggedVariable], log_times=times)\n",
    "        result = output[loggedVariable]\n",
    "\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to import the tumour growth data that we cleaned in a previous [notebook](https://github.com/DavAug/ErlotinibGefitinib/blob/master/notebooks/control_growth/data_preparation.ipynb) to define the likelihood of the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load cleaned LXF and VXF data sets.\n",
    "#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Get path of current working directory\n",
    "path = os.getcwd()\n",
    "\n",
    "# Read cleaned LXF A677 control growth data\n",
    "lxf_data = pd.read_csv(path + '/data/lxf_control_growth.csv')\n",
    "\n",
    "# Read cleaned VXF A341 control growth data\n",
    "vxf_data = pd.read_csv(path + '/data/vxf_control_growth.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `pints.ForwardModel` implementing the structural model for the tumour growth and the time-series data of the control tumour growth, we can now construct the likelihood for the model parameters $\\psi $ and $\\theta $.\n",
    "\n",
    "(Note that we still have to create likelihoods for the individual mice, because myokit does not allow multiple measurements at the same time point.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood for LXF A677 tumour growth model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Construct likelihood for LXF A677 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = lxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = lxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = lxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = lxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "lxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood for VXF A341 tumour growth model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Construct likelihood for VXF A341 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = vxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = vxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = vxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = vxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "vxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifiability check\n",
    "\n",
    "some explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running...\nRound 1\nRound 2\nRound 3\nRound 4\nRound 5\nDone!\n \nEstimates: \nInitial tumour volume [cm^3]:  [1.34796622 0.93024172 1.34753463 1.34111851 1.27354206]\nExponential growth rate \\lambda _0 [1/day]:  [ 3.66072941e+02 -2.50009666e-01  1.82867188e+02 -1.01997319e+01\n -3.28346683e-02]\nLinear growth rate \\lambda _1 [cm^3/day]:  [  0.3587859    0.31194863   0.35883914   0.35750309 144.84249923]\nStandard-deviation of base-level noise [cm^3]:  [4.51403325 4.50053914 4.51405733 4.51374813 8.34865767]\n"
    }
   ],
   "source": [
    "#\n",
    "# Check identifiability of LXF A677 problem.\n",
    "#\n",
    "\n",
    "import pints\n",
    "\n",
    "\n",
    "# Get number of optimisation runs and number of parameters\n",
    "n = 5\n",
    "n_parameters = lxf_log_likelihood.n_parameters()\n",
    "\n",
    "# Initial guess of parameters\n",
    "parameters = np.array([\n",
    "    [10E-2, 10E-2, 10E-2, 10E-2],\n",
    "    [10E-1, 10E-1, 10E-1, 10E-1],\n",
    "    [10E0, 10E0, 10E0, 10E0],\n",
    "    [10E1, 10E1, 10E1, 10E1],\n",
    "    [10E2, 10E2, 10E2, 10E2]])\n",
    "\n",
    "# Create estimate container\n",
    "estimates = np.empty(shape=(n, n_parameters))\n",
    "\n",
    "print('Running...')\n",
    "# estimate parameters\n",
    "for i in range(n):\n",
    "    print('Round %d' % (i+1))\n",
    "\n",
    "    # Initial guess of parameters\n",
    "    params = parameters[i, :]\n",
    "\n",
    "    # Choose optimisation method\n",
    "    optimiser = pints.CMAES\n",
    "\n",
    "    # Create optimisation object\n",
    "    opt = pints.OptimisationController(\n",
    "        function=lxf_log_likelihood,\n",
    "        x0=params,\n",
    "        method=optimiser)\n",
    "\n",
    "    # Disable logging mode\n",
    "    opt.set_log_to_screen(False)\n",
    "\n",
    "    # Parallelise optimisation\n",
    "    opt.set_parallel(True)\n",
    "\n",
    "    # Optimise likelihood\n",
    "    est, _ = opt.run()\n",
    "\n",
    "    # Save estimates\n",
    "    estimates[i, :] = est\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print(' ')\n",
    "print('Estimates: ')\n",
    "print('Initial tumour volume [cm^3]: ', estimates[:, 0])\n",
    "print('Exponential growth rate \\lambda _0 [1/day]: ', estimates[:, 1])\n",
    "print('Linear growth rate \\lambda _1 [cm^3/day]: ', estimates[:, 2])\n",
    "print('Standard deviation of base-level noise [cm^3]: ', estimates[:, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-transform structural model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define pints model wrapper with log-transformed parameters.\n",
    "#\n",
    "\n",
    "import myokit\n",
    "import numpy as np\n",
    "import pints\n",
    "\n",
    "from pkpd import model as model\n",
    "\n",
    "\n",
    "# Wrap myokit model, so it can be used with pints\n",
    "class PintsModel(pints.ForwardModel):\n",
    "    def __init__(self):\n",
    "        # Create myokit model\n",
    "        model = m.create_tumour_growth_model()\n",
    "\n",
    "        # Create simulator\n",
    "        self.sim = myokit.Simulation(model)\n",
    "\n",
    "    def n_parameters(self):\n",
    "        \"\"\"\n",
    "        Number of parameters to fit. Here initial V^s_T, lambda_0, lambda_1\n",
    "        \"\"\"\n",
    "        return 3\n",
    "\n",
    "    def n_outputs(self):\n",
    "        return 1\n",
    "\n",
    "    def simulate(self, log_parameters, times):\n",
    "        # Reset simulation\n",
    "        self.sim.reset()\n",
    "\n",
    "        # Sort input parameters\n",
    "        initial_volume, lambda_0, lambda_1 = np.exp(log_parameters)\n",
    "\n",
    "        # Set initial condition\n",
    "        self.sim.set_state([initial_volume])\n",
    "\n",
    "        # Set growth constants\n",
    "        self.sim.set_constant('central.lambda_0', lambda_0)\n",
    "        self.sim.set_constant('central.lambda_1', lambda_1)\n",
    "\n",
    "        # Define logged variable\n",
    "        loggedVariable = 'central.volume_t'\n",
    "\n",
    "        # Simulate\n",
    "        output = self.sim.run(times[-1] + 1, log=[loggedVariable], log_times=times)\n",
    "        result = output[loggedVariable]\n",
    "\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Construct likelihood for LXF A677 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = lxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = lxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = lxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = lxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "lxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Construct likelihood for VXF A341 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = vxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = vxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = vxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = vxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "vxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running...\nRound 1\nRound 2\nRound 3\nRound 4\nRound 5\nDone!\n \nEstimates: \nInitial tumour volume [cm^3]:  [1.34771772 1.34795312 1.34770143 1.34740049 1.34745836]\nExponential growth rate \\lambda _0 [1/day]:  [2.03554194e+03 3.66076628e+02 4.82434343e+13 8.42074049e+02\n 8.29368456e+02]\nLinear growth rate \\lambda _1 [cm^3/day]:  [0.35874319 0.35878604 0.358735   0.35877458 0.35877169]\nStandard-deviation of base-level noise [cm^3]:  [4.51404352 4.51403982 4.51404453 4.51404477 4.51404398]\n"
    }
   ],
   "source": [
    "#\n",
    "# Check identifiability of LXF A677 problem.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pints\n",
    "\n",
    "\n",
    "# Get number of optimisation runs and number of parameters\n",
    "n = 5\n",
    "n_parameters = lxf_log_likelihood.n_parameters()\n",
    "\n",
    "# Initial guess of parameters [initial volume, lambda_0, lambda_1, sigma]\n",
    "log_parameters_and_sigma = np.array([0.0, 0.0, 0.0, 1.0])\n",
    "\n",
    "# Standard deviatoin around initial guesses\n",
    "sigma0 = np.array([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "# Create estimate container\n",
    "estimates = np.empty(shape=(n, n_parameters))\n",
    "\n",
    "print('Running...')\n",
    "# estimate parameters\n",
    "for i in range(n):\n",
    "    print('Round %d' % (i+1))\n",
    "\n",
    "    # Choose optimisation method\n",
    "    optimiser = pints.CMAES\n",
    "\n",
    "    # Create optimisation object\n",
    "    opt = pints.OptimisationController(\n",
    "        function=lxf_log_likelihood,\n",
    "        x0=log_parameters_and_sigma,\n",
    "        sigma0=sigma0,\n",
    "        method=optimiser)\n",
    "\n",
    "    # Disable logging mode\n",
    "    opt.set_log_to_screen(False)\n",
    "\n",
    "    # Parallelise optimisation\n",
    "    opt.set_parallel(True)\n",
    "\n",
    "    # Optimise likelihood\n",
    "    log_est, _ = opt.run()\n",
    "\n",
    "    # Save estimates (transform log-parameters, but keep sigma)\n",
    "    estimates[i, :-1] = np.exp(log_est[:-1])\n",
    "    estimates[i, -1] =log_est[-1]\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print(' ')\n",
    "print('Estimates: ')\n",
    "print('Initial tumour volume [cm^3]: ', estimates[:, 0])\n",
    "print('Exponential growth rate \\lambda _0 [1/day]: ', estimates[:, 1])\n",
    "print('Linear growth rate \\lambda _1 [cm^3/day]: ', estimates[:, 2])\n",
    "print('Standard deviation of base-level noise [cm^3]: ', estimates[:, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-dimensionalise parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define pints model wrapper such that myokit model can be used for inference.\n",
    "#\n",
    "# Input parameters are scaled to an expected scale and log-trasnformed to stabilise\n",
    "# inference.\n",
    "#\n",
    "\n",
    "import myokit\n",
    "import numpy as np\n",
    "import pints\n",
    "\n",
    "from pkpd import model as model\n",
    "\n",
    "\n",
    "# Wrap myokit model, so it can be used with pints\n",
    "class PintsModel(pints.ForwardModel):\n",
    "    def __init__(self):\n",
    "        # Create myokit model\n",
    "        model = m.create_tumour_growth_model()\n",
    "\n",
    "        # Create simulator\n",
    "        self.sim = myokit.Simulation(model)\n",
    "\n",
    "        # Characteristic scale [intial volume, lambda_0, lambda_1]\n",
    "        self._char_scale = np.array([1.3, 3E02, 0.35])\n",
    "\n",
    "    def n_parameters(self):\n",
    "        \"\"\"\n",
    "        Number of parameters to fit. Here initial V^s_T, lambda_0, lambda_1\n",
    "        \"\"\"\n",
    "        return 3\n",
    "\n",
    "    def n_outputs(self):\n",
    "        return 1\n",
    "\n",
    "    def simulate(self, log_parameters, times):\n",
    "        # Reset simulation\n",
    "        self.sim.reset()\n",
    "\n",
    "        # Sort input parameters\n",
    "        initial_volume, lambda_0, lambda_1 = np.exp(log_parameters) * self._char_scale\n",
    "\n",
    "        # Set initial condition\n",
    "        self.sim.set_state([initial_volume])\n",
    "\n",
    "        # Set growth constants\n",
    "        self.sim.set_constant('central.lambda_0', lambda_0)\n",
    "        self.sim.set_constant('central.lambda_1', lambda_1)\n",
    "\n",
    "        # Define logged variable\n",
    "        loggedVariable = 'central.volume_t'\n",
    "\n",
    "        # Simulate\n",
    "        output = self.sim.run(times[-1] + 1, log=[loggedVariable], log_times=times)\n",
    "        result = output[loggedVariable]\n",
    "\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Construct likelihood for LXF A677 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = lxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = lxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = lxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = lxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "lxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)#\n",
    "# Construct likelihood for LXF A677 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = lxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = lxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = lxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = lxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "lxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Construct likelihood for VXF A341 tumour growth model parameters.\n",
    "#\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pints\n",
    "\n",
    "\n",
    "# Create inverse problem for each mouse ID\n",
    "mouse_ids = vxf_data['#ID'].unique()\n",
    "log_likelihoods = []\n",
    "for ids in mouse_ids:\n",
    "    # Create mask for mouse with specfied ID\n",
    "    mouse_mask = vxf_data['#ID'] == ids\n",
    "\n",
    "    # Get relevant time points\n",
    "    times = vxf_data[mouse_mask]['TIME in day'].to_numpy()\n",
    "\n",
    "    # Get measured tumour volumes\n",
    "    observed_volumes = vxf_data[mouse_mask]['TUMOUR VOLUME in cm^3'].to_numpy()\n",
    "\n",
    "    # Create inverse problem\n",
    "    problem = pints.SingleOutputProblem(PintsModel(), times, observed_volumes)\n",
    "\n",
    "    # Create Gaussian log-likelihood TODO: Change to combined error model\n",
    "    log_likelihoods.append(pints.GaussianLogLikelihood(problem))\n",
    "\n",
    "# Create one log_likelihood for the inference from the individual problems\n",
    "vxf_log_likelihood = pints.SumOfIndependentLogPDFs(log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Running...\nRound 1\nRound 2\nRound 3\nRound 4\nRound 5\nDone!\n \nEstimates: \nInitial tumour volume [cm^3]:  [1.34797863 1.34796979 1.34746332 1.3475335  1.34739554]\nExponential growth rate \\lambda _0 [1/day]:  [366.0679323  366.07135534 829.36515154 182.86743461 842.07710061]\nLinear growth rate \\lambda _1 [cm^3/day]:  [0.35878428 0.35878532 0.35877156 0.35883931 0.35877458]\nStandard deviation of base-level noise [cm^3]:  [4.5140468  4.51403935 4.51404432 4.51405563 4.51404329]\n"
    }
   ],
   "source": [
    "#\n",
    "# Check identifiability of LXF A677 problem.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pints\n",
    "\n",
    "\n",
    "# Get number of optimisation runs and number of parameters\n",
    "n = 5\n",
    "n_parameters = lxf_log_likelihood.n_parameters()\n",
    "\n",
    "# Initial guess of parameters [initial volume, lambda_0, lambda_1, sigma]\n",
    "log_parameters_and_sigma = np.array([0.0, 0.0, 0.0, 1.0])\n",
    "\n",
    "# Standard deviatoin around initial guesses\n",
    "sigma0 = np.array([0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "# Create estimate container\n",
    "estimates = np.empty(shape=(n, n_parameters))\n",
    "\n",
    "print('Running...')\n",
    "# estimate parameters\n",
    "for i in range(n):\n",
    "    print('Round %d' % (i+1))\n",
    "\n",
    "    # Choose optimisation method\n",
    "    optimiser = pints.CMAES\n",
    "\n",
    "    # Create optimisation object\n",
    "    opt = pints.OptimisationController(\n",
    "        function=lxf_log_likelihood,\n",
    "        x0=log_parameters_and_sigma,\n",
    "        sigma0=sigma0,\n",
    "        method=optimiser)\n",
    "\n",
    "    # Disable logging mode\n",
    "    opt.set_log_to_screen(False)\n",
    "\n",
    "    # Parallelise optimisation\n",
    "    opt.set_parallel(True)\n",
    "\n",
    "    # Optimise likelihood\n",
    "    est, _ = opt.run()\n",
    "\n",
    "    # Transform parameters back and save estimates\n",
    "    char_scale = np.array([1.3, 3E02, 0.35])  # Defined in PintsModel\n",
    "    estimates[i, :-1] = np.exp(est[:-1]) * char_scale\n",
    "    estimates[i, -1] = est[-1]\n",
    "\n",
    "print('Done!')\n",
    "\n",
    "print(' ')\n",
    "print('Estimates: ')\n",
    "print('Initial tumour volume [cm^3]: ', estimates[:, 0])\n",
    "print('Exponential growth rate \\lambda _0 [1/day]: ', estimates[:, 1])\n",
    "print('Linear growth rate \\lambda _1 [cm^3/day]: ', estimates[:, 2])\n",
    "print('Standard deviation of base-level noise [cm^3]: ', estimates[:, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "- <a name=\"ref1\"> [1] </a> Eigenmann et. al., Combining Nonclinical Experiments with Translational PKPD Modeling to Differentiate Erlotinib and Gefitinib, Mol Cancer Ther (2016)\n",
    "- <a name=\"ref2\"> [2] </a> Bellman, R. & Åström, K. On structural identifiability.Mathematical Biosciences7, 329 – 339 (1970)\n",
    "- <a name=\"ref2\"> [3] </a> Janzén, D. L. I.et al.Parameter identifiability of fundamental pharmacodynamic models.Frontiers in Physiology7, 590 (2016)\n",
    "- <a name=\"ref2\"> [4] </a> Lavielle, M. & Aarons, L. What do we mean by identifiability in mixed effects models?Journal of Pharmacoki-netics and Pharmacodynamics43, 111–122 (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bitvenvvenv16524ab6d9c04010a849c4faf6663120",
   "display_name": "Python 3.7.5 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}